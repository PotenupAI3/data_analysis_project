{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162f950d",
   "metadata": {},
   "source": [
    "# 1. 청년 순이동률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "eca3f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", 1000)\n",
    "\n",
    "admin = pd.read_csv(\"../../data/행정구역코드.csv\")\n",
    "admin[\"행정구역코드\"] = admin[\"행정구역코드\"].astype(str)\n",
    "\n",
    "# 수도권 + 광역시 제외\n",
    "exclude_prefix = [\"11\", \"31\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\"]\n",
    "sigun = admin[~admin[\"행정구역코드\"].str[:2].isin(exclude_prefix)].copy()\n",
    "\n",
    "objL1 = \"+\".join(sigun[\"행정구역코드\"].tolist()) + \"+\"\n",
    "\n",
    "BASE_URL = \"https://kosis.kr/openapi/Param/statisticsParameterData.do\"\n",
    "\n",
    "params = {\n",
    "    \"method\": \"getList\",\n",
    "    \"apiKey\": \"ZWRiNzEyMzEwNGI5OWQ3NzcxNGM1MDNiOGJkOTQ0Y2M=\",\n",
    "    \"orgId\": \"101\",\n",
    "    \"tblId\": \"DT_1YL20642\",\n",
    "    \"itmId\": \"T001+\",\n",
    "    \"objL1\": objL1,\n",
    "    \"objL2\": \"21+22+23+\",\n",
    "    \"format\": \"json\",\n",
    "    \"jsonVD\": \"Y\",\n",
    "    \"prdSe\": \"Y\",\n",
    "    \"newEstPrdCnt\": \"3\",\n",
    "}\n",
    "\n",
    "response = requests.get(BASE_URL, params=params)\n",
    "df_raw = pd.DataFrame(response.json())\n",
    "\n",
    "df = df_raw[\n",
    "    [\n",
    "        \"PRD_DE\",  # 연도\n",
    "        \"C1\",  # 행정코드\n",
    "        \"C1_NM\",  # 지역명\n",
    "        \"C2_NM\",  # 지표명 (순이동률 / 순이동)\n",
    "        \"DT\",  # 값\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "df.columns = [\"연도\", \"행정코드\", \"지역명\", \"지표\", \"값\"]\n",
    "\n",
    "df[\"연도\"] = df[\"연도\"].astype(int)\n",
    "df[\"행정코드\"] = df[\"행정코드\"].astype(str)\n",
    "df[\"값\"] = pd.to_numeric(df[\"값\"], errors=\"coerce\")\n",
    "\n",
    "rate_df = df[df[\"지표\"].str.contains(\"순이동률\")].copy()\n",
    "count_df = df[df[\"지표\"].str.contains(\"순이동\") & ~df[\"지표\"].str.contains(\"률\")].copy()\n",
    "\n",
    "rate_df.rename(columns={\"값\": \"청년순이동률\"}, inplace=True)\n",
    "count_df.rename(columns={\"값\": \"청년순이동\"}, inplace=True)\n",
    "\n",
    "pivot_rate_df = rate_df.pivot_table(\n",
    "    index=[\"행정코드\", \"지역명\"], columns=\"연도\", values=\"청년순이동률\", aggfunc=\"sum\"\n",
    ").reset_index()\n",
    "\n",
    "pivot_count_df = count_df.pivot_table(\n",
    "    index=[\"행정코드\", \"지역명\"], columns=\"연도\", values=\"청년순이동\", aggfunc=\"sum\"\n",
    ").reset_index()\n",
    "\n",
    "# =========================\n",
    "# 0) 입력: pivot_rate_df (행정코드, 지역명, 연도컬럼들)\n",
    "# =========================\n",
    "\n",
    "# 최근 3개 연도 자동 선택 (newEstPrdCnt=3이지만 혹시 더 들어와도 안전)\n",
    "year_cols = sorted(\n",
    "    [c for c in pivot_rate_df.columns if isinstance(c, (int, np.integer))]\n",
    ")\n",
    "target_years = year_cols[-3:]  # 예: [2022, 2023, 2024]\n",
    "\n",
    "# 가중치(최근일수록 중요)\n",
    "w = np.array([0.2, 0.3, 0.5], dtype=float)\n",
    "w = w / w.sum()\n",
    "\n",
    "# 점수 가중치 (프로젝트용 기본값)\n",
    "alpha = 0.4  # slope (방향성)\n",
    "beta = 0.5  # weighted_mean (최근 수준)\n",
    "gamma = 0.1  # std (변동성 페널티)\n",
    "\n",
    "score_df = pivot_rate_df[[\"행정코드\", \"지역명\"] + target_years].copy()\n",
    "y = score_df[target_years].to_numpy(dtype=float)\n",
    "\n",
    "# =========================\n",
    "# 1) 추세 기울기(slope): 선형회귀의 기울기\n",
    "#    x = [0,1,2]로 고정 (연도 간격 동일 가정)\n",
    "# =========================\n",
    "x = np.arange(len(target_years), dtype=float)\n",
    "x_centered = x - x.mean()\n",
    "x_denom = (x_centered**2).sum()\n",
    "\n",
    "# slope = cov(x,y)/var(x) (row-wise)\n",
    "y_centered = y - np.nanmean(y, axis=1, keepdims=True)\n",
    "slope = np.nansum(x_centered * y_centered, axis=1) / x_denom\n",
    "\n",
    "# =========================\n",
    "# 2) 최근가중평균(weighted mean)\n",
    "# =========================\n",
    "weighted_mean = np.nansum(y * w, axis=1)\n",
    "\n",
    "# =========================\n",
    "# 3) 변동성(std)\n",
    "# =========================\n",
    "std = np.nanstd(y, axis=1)\n",
    "\n",
    "score_df[\"slope\"] = slope\n",
    "score_df[\"weighted_mean\"] = weighted_mean\n",
    "score_df[\"std\"] = std\n",
    "\n",
    "# =========================\n",
    "# 4) 스케일 보정: z-score 표준화 (권장)\n",
    "#    - slope, weighted_mean, std의 단위/범위가 다를 수 있음\n",
    "# =========================\n",
    "for col in [\"slope\", \"weighted_mean\", \"std\"]:\n",
    "    mu = score_df[col].mean(skipna=True)\n",
    "    sd = score_df[col].std(skipna=True)\n",
    "    score_df[f\"z_{col}\"] = (score_df[col] - mu) / (sd if sd != 0 else 1)\n",
    "\n",
    "# 최종 점수\n",
    "score_df[\"top5_score\"] = (\n",
    "    alpha * score_df[\"z_slope\"]\n",
    "    + beta * score_df[\"z_weighted_mean\"]\n",
    "    - gamma * score_df[\"z_std\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5) 필터: \"증가\"의 최소 조건\n",
    "#    옵션 A: 최신년도 > 0 (가장 강한 필터)\n",
    "#    옵션 B: 최근 2년 평균 > 0 (조금 완화)\n",
    "# =========================\n",
    "latest_year = target_years[-1]\n",
    "recent2_mean = score_df[target_years[-2:]].mean(axis=1)\n",
    "\n",
    "# 원하는 필터 하나 선택해서 쓰면 됨\n",
    "score_df_filtered = score_df[(score_df[latest_year] > 0) & (recent2_mean > 0)].copy()\n",
    "\n",
    "# =========================\n",
    "# 6) TOP5 뽑기 + 보기 좋게 정렬\n",
    "# =========================\n",
    "top5 = score_df_filtered.sort_values(\"top5_score\", ascending=False).head(5)[\n",
    "    [\"행정코드\", \"지역명\"]\n",
    "    + target_years\n",
    "    + [\"slope\", \"weighted_mean\", \"std\", \"top5_score\"]\n",
    "]\n",
    "\n",
    "top10 = score_df_filtered.sort_values(\"top5_score\", ascending=False).head(10)[\n",
    "    [\"행정코드\", \"지역명\"]\n",
    "    + target_years\n",
    "    + [\"slope\", \"weighted_mean\", \"std\", \"top5_score\"]\n",
    "]\n",
    "\n",
    "year_cols = [col for col in pivot_rate_df.columns if isinstance(col, int)]\n",
    "\n",
    "# 단순 평균\n",
    "pivot_rate_df[\"평균\"] = pivot_rate_df[year_cols].mean(axis=1)\n",
    "\n",
    "# 중앙값\n",
    "pivot_rate_df[\"중앙값\"] = pivot_rate_df[year_cols].median(axis=1)\n",
    "\n",
    "n = len(year_cols)\n",
    "mid = n // 2\n",
    "\n",
    "pivot_rate_df[\"증가율\"] = pivot_rate_df[year_cols[mid:]].mean(axis=1) - pivot_rate_df[\n",
    "    year_cols[:mid]\n",
    "].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf774b",
   "metadata": {},
   "source": [
    "## 인구 십만명당 문화기반시설수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "0e3bdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인구 십만명당 문화기반시설수(시도/시/군/구)\n",
    "# https://kosis.kr/statHtml/statHtml.do?orgId=101&tblId=DT_1YL20931&conn_path=I2\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "admin = pd.read_csv(\"../../data/행정구역코드.csv\")\n",
    "admin[\"행정구역코드\"] = admin[\"행정구역코드\"].astype(str)\n",
    "\n",
    "# 수도권 + 광역시 제외\n",
    "exclude_prefix = [\"11\", \"31\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\"]\n",
    "sigun = admin[~admin[\"행정구역코드\"].str[:2].isin(exclude_prefix)].copy()\n",
    "\n",
    "objL1 = \"+\".join(sigun[\"행정구역코드\"].tolist()) + \"+34360+35310+36420+\"\n",
    "\n",
    "url = \"https://kosis.kr/openapi/Param/statisticsParameterData.do\"\n",
    "\n",
    "params = {\n",
    "    \"method\": \"getList\",\n",
    "    \"apiKey\": os.getenv(\"KOSIS_API_KEY\"),\n",
    "    \"orgId\": \"101\",\n",
    "    \"tblId\": \"DT_1YL20931\",\n",
    "    \"itmId\": \"T001+\",\n",
    "    \"objL1\": objL1,\n",
    "    \"format\": \"json\",\n",
    "    \"jsonVD\": \"Y\",\n",
    "    \"prdSe\": \"Y\",\n",
    "    \"newEstPrdCnt\": \"1\",  # 최근 1개 연도 -> 2024년 기준\n",
    "}\n",
    "\n",
    "res = requests.get(url, params=params)\n",
    "\n",
    "data = res.json()\n",
    "culture_df = pd.DataFrame(data)\n",
    "\n",
    "culture_df[\"DT\"] = pd.to_numeric(culture_df[\"DT\"], errors=\"coerce\")\n",
    "culture_clean = culture_df[[\"C1_NM\", \"DT\"]].copy()\n",
    "culture_clean.columns = [\"C1_NM\", \"문화시설수\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ttop10와 culture_clean 병합 (지역명 기준)\n",
    "merged_df = pd.merge(\n",
    "    top10, culture_clean, left_on=\"지역명\", right_on=\"C1_NM\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# top5_score 기준으로 정렬\n",
    "merged_df = merged_df.sort_values(by=\"top5_score\", ascending=False)\n",
    "\n",
    "# 산점도 그래프\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(\n",
    "    merged_df[\"문화시설수\"],\n",
    "    merged_df[\"top5_score\"],\n",
    "    s=150,\n",
    "    alpha=0.6,\n",
    "    color=\"steelblue\",\n",
    ")\n",
    "\n",
    "# 지역 레이블 표시\n",
    "for _, row in merged_df.iterrows():\n",
    "    plt.text(\n",
    "        row[\"문화시설수\"],\n",
    "        row[\"top5_score\"],\n",
    "        row[\"지역명\"],\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "# 기준선 추가\n",
    "plt.axhline(\n",
    "    merged_df[\"top5_score\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    label=f\"청년유입 점수 중앙값: {merged_df['top5_score'].median():.2f}\",\n",
    ")\n",
    "plt.axvline(\n",
    "    merged_df[\"문화시설수\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=f\"문화시설수 중앙값: {merged_df['문화시설수'].median():.2f}\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"인구 10만명당 문화기반시설 수\", fontsize=12)\n",
    "plt.ylabel(\"청년유입 점수\", fontsize=12)\n",
    "plt.title(\"청년유입 상위 지역의 문화시설 수\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16a795",
   "metadata": {},
   "source": [
    "## 공공도서관"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50990c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "library_df = pd.read_excel(\n",
    "    \"./data/2025 전국 문화기반시설 총람.xlsx\",\n",
    "    sheet_name=\"공공도서관\",\n",
    "    skiprows=2,\n",
    "    header=3,\n",
    ")\n",
    "\n",
    "library_df = library_df.rename(columns={\"Unnamed: 2\": \"C1_NM\"})\n",
    "library_df = (\n",
    "    library_df.groupby([\"Unnamed: 1\", \"C1_NM\"]).size().reset_index(name=\"공공도서관수\")\n",
    ")\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ttop10와 library_df 병합 (지역명 기준)\n",
    "merged_df = pd.merge(top10, library_df, left_on=\"지역명\", right_on=\"C1_NM\", how=\"inner\")\n",
    "\n",
    "# top5_score 기준으로 정렬\n",
    "merged_df = merged_df.sort_values(by=\"top5_score\", ascending=False)\n",
    "\n",
    "# 산점도 그래프\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(\n",
    "    merged_df[\"공공도서관수\"],\n",
    "    merged_df[\"top5_score\"],\n",
    "    s=150,\n",
    "    alpha=0.6,\n",
    "    color=\"steelblue\",\n",
    ")\n",
    "\n",
    "# 지역 레이블 표시\n",
    "for _, row in merged_df.iterrows():\n",
    "    plt.text(\n",
    "        row[\"공공도서관수\"],\n",
    "        row[\"top5_score\"],\n",
    "        row[\"지역명\"],\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "# 기준선 추가\n",
    "plt.axhline(\n",
    "    merged_df[\"top5_score\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    label=f\"청년유입 점수 중앙값: {merged_df['top5_score'].median():.2f}\",\n",
    ")\n",
    "plt.axvline(\n",
    "    merged_df[\"공공도서관수\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=f\"공공도서관수 중앙값: {merged_df['공공도서관수'].median():.2f}\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"공공도서관 수\", fontsize=12)\n",
    "plt.ylabel(\"청년유입 점수\", fontsize=12)\n",
    "plt.title(\"청년유입 상위 지역의 공공도서관 수\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fcdb7e",
   "metadata": {},
   "source": [
    "## 생활문화센터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e936ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "culture_center_df = pd.read_excel(\n",
    "    \"./data/2025 전국 문화기반시설 총람.xlsx\",\n",
    "    sheet_name=\"생활문화센터\",\n",
    "    skiprows=2,\n",
    "    header=2,\n",
    ")\n",
    "\n",
    "culture_center_df = culture_center_df.rename(columns={\"Unnamed: 2\": \"C1_NM\"})\n",
    "culture_center_df = (\n",
    "    culture_center_df.groupby([\"Unnamed: 1\", \"C1_NM\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"생활문화센터수\")\n",
    ")\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ttop10와 culture_center_df 병합 (지역명 기준)\n",
    "merged_df = pd.merge(\n",
    "    top10, culture_center_df, left_on=\"지역명\", right_on=\"C1_NM\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# top5_score 기준으로 정렬\n",
    "merged_df = merged_df.sort_values(by=\"top5_score\", ascending=False)\n",
    "\n",
    "# 산점도 그래프\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(\n",
    "    merged_df[\"생활문화센터수\"],\n",
    "    merged_df[\"top5_score\"],\n",
    "    s=150,\n",
    "    alpha=0.6,\n",
    "    color=\"steelblue\",\n",
    ")\n",
    "\n",
    "# 지역 레이블 표시\n",
    "for _, row in merged_df.iterrows():\n",
    "    plt.text(\n",
    "        row[\"생활문화센터수\"],\n",
    "        row[\"top5_score\"],\n",
    "        row[\"지역명\"],\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "# 기준선 추가\n",
    "plt.axhline(\n",
    "    merged_df[\"top5_score\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    label=f\"청년유입 점수 중앙값: {merged_df['top5_score'].median():.2f}\",\n",
    ")\n",
    "plt.axvline(\n",
    "    merged_df[\"생활문화센터수\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=f\"생활문화센터수 중앙값: {merged_df['생활문화센터수'].median():.2f}\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"생활문화센터 수\", fontsize=12)\n",
    "plt.ylabel(\"청년유입 점수\", fontsize=12)\n",
    "plt.title(\"청년유입 상위 지역의 생활문화센터 수\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a06121",
   "metadata": {},
   "source": [
    "## 영화관"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ac8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "theater_df = pd.read_csv(\"./data/KC_497_DMSTC_MCST_THEART_2025.csv\")\n",
    "\n",
    "theater_df = (\n",
    "    theater_df.groupby([\"sido_nm\", \"sgg_nm\"]).size().reset_index(name=\"영화관수\")\n",
    ")\n",
    "\n",
    "theater_use = theater_df.copy()\n",
    "\n",
    "# 행정명 정규화\n",
    "theater_use[\"C1_NM\"] = theater_use[\"sgg_nm\"]\n",
    "\n",
    "# ○○시○○구 → ○○시 (구가 있는 경우만)\n",
    "theater_use[\"C1_NM\"] = theater_use[\"C1_NM\"].str.replace(\n",
    "    r\"(.*?시).+구$\", r\"\\1\", regex=True\n",
    ")\n",
    "\n",
    "# 시군 단위 영화관 개수 합산\n",
    "theater_df2 = theater_use.groupby(\"C1_NM\", as_index=False)[\"영화관수\"].sum()\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ttop10와 theater_df2 병합 (지역명 기준)\n",
    "merged_df = pd.merge(\n",
    "    top10, theater_df2, left_on=\"지역명\", right_on=\"C1_NM\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# top5_score 기준으로 정렬\n",
    "merged_df = merged_df.sort_values(by=\"top5_score\", ascending=False)\n",
    "\n",
    "# 산점도 그래프\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(\n",
    "    merged_df[\"영화관수\"],\n",
    "    merged_df[\"top5_score\"],\n",
    "    s=150,\n",
    "    alpha=0.6,\n",
    "    color=\"steelblue\",\n",
    ")\n",
    "\n",
    "# 지역 레이블 표시\n",
    "for _, row in merged_df.iterrows():\n",
    "    plt.text(\n",
    "        row[\"영화관수\"],\n",
    "        row[\"top5_score\"],\n",
    "        row[\"지역명\"],\n",
    "        fontsize=11,\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "# 기준선 추가\n",
    "plt.axhline(\n",
    "    merged_df[\"top5_score\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    label=f\"청년유입 점수 중앙값: {merged_df['top5_score'].median():.2f}\",\n",
    ")\n",
    "plt.axvline(\n",
    "    merged_df[\"영화관수\"].median(),\n",
    "    linestyle=\"--\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=f\"영화관수 중앙값: {merged_df['영화관수'].median():.2f}\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"영화관 수\", fontsize=12)\n",
    "plt.ylabel(\"청년유입 점수\", fontsize=12)\n",
    "plt.title(\"청년유입 상위 지역의 영화관 수\", fontsize=14, fontweight=\"bold\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f633e7f",
   "metadata": {},
   "source": [
    "# 2. 유튜브 댓글 크롤링 후 워드 클라우드, LDA 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e65da32",
   "metadata": {},
   "source": [
    "## https://www.youtube.com/watch?v=kxkacVPgTIk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7c4e7",
   "metadata": {},
   "source": [
    "### 유튜브 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "\n",
    "part = \"snippet\"\n",
    "videoId = \"kxkacVPgTIk\"\n",
    "key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "maxResults = 100\n",
    "textFormat = \"plainText\"\n",
    "nextPageToken = None\n",
    "\n",
    "dataList = []\n",
    "max_rep = 50\n",
    "\n",
    "for i in range(max_rep):\n",
    "    url = f\"{baseUrl}?part={part}&videoId={videoId}&key={key}&maxResults={maxResults}&textFormat={textFormat}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        nextPageToken = data.get(\"nextPageToken\")\n",
    "\n",
    "        for i in range(len(data[\"items\"])):\n",
    "            dataList.append(data[\"items\"][i][\"snippet\"][\"topLevelComment\"][\"snippet\"])\n",
    "\n",
    "        if nextPageToken is None:\n",
    "            break\n",
    "\n",
    "print(len(dataList))\n",
    "\n",
    "df = pd.DataFrame(dataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c697c9",
   "metadata": {},
   "source": [
    "### 워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8653738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from kiwipiepy import Kiwi\n",
    "from collections import Counter\n",
    "\n",
    "kiwi = Kiwi()\n",
    "word_list = []\n",
    "\n",
    "for sent in df[\"textOriginal\"]:\n",
    "    clean_sent = re.sub(\"[^0-9a-zA-Z가-힣\\s]\", \"\", sent)\n",
    "    tokens = kiwi.analyze(clean_sent)[0][0]\n",
    "    sub_list = []\n",
    "\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        pos = token.tag\n",
    "\n",
    "        if pos == \"NNG\" and len(word) > 1:\n",
    "            sub_list.append(word)\n",
    "\n",
    "    word_list.extend(sub_list)\n",
    "\n",
    "print(len(word_list))\n",
    "\n",
    "counter = Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "wc = WordCloud(\n",
    "    font_path=\"C:\\Windows\\Fonts\\malgun.ttf\",\n",
    "    background_color=\"white\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    prefer_horizontal=1.0,\n",
    ")\n",
    "\n",
    "wc.generate_from_frequencies(counter)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8104397",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_df=0.1, min_df=2, max_features=1000, ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "feat_vec = count_vectorizer.fit_transform(word_list)\n",
    "feat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_vec = pd.DataFrame(\n",
    "    feat_vec.toarray(), columns=count_vectorizer.get_feature_names_out()\n",
    ")\n",
    "df_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3)\n",
    "lda.fit(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9430152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.lda_model\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.lda_model.prepare(lda, feat_vec, count_vectorizer)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "3aacb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.save_html(vis, \"lda_vis.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a9486",
   "metadata": {},
   "source": [
    "## https://www.youtube.com/watch?v=ZghVVrcYAuc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa07dc58",
   "metadata": {},
   "source": [
    "### 유튜브 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb10c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "baseUrl = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "\n",
    "part = \"snippet\"\n",
    "videoId = \"ZghVVrcYAuc\"\n",
    "key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "maxResults = 100\n",
    "textFormat = \"plainText\"\n",
    "nextPageToken = None\n",
    "\n",
    "dataList2 = []\n",
    "max_rep = 50\n",
    "\n",
    "for i in range(max_rep):\n",
    "    url = f\"{baseUrl}?part={part}&videoId={videoId}&key={key}&maxResults={maxResults}&textFormat={textFormat}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        nextPageToken = data.get(\"nextPageToken\")\n",
    "\n",
    "        for i in range(len(data[\"items\"])):\n",
    "            dataList2.append(data[\"items\"][i][\"snippet\"][\"topLevelComment\"][\"snippet\"])\n",
    "\n",
    "        if nextPageToken is None:\n",
    "            break\n",
    "\n",
    "print(len(dataList2))\n",
    "\n",
    "df = pd.DataFrame(dataList2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e854b",
   "metadata": {},
   "source": [
    "### 워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from kiwipiepy import Kiwi\n",
    "from collections import Counter\n",
    "\n",
    "kiwi = Kiwi()\n",
    "word_list2 = []\n",
    "\n",
    "for sent in df[\"textOriginal\"]:\n",
    "    clean_sent = re.sub(\"[^0-9a-zA-Z가-힣\\s]\", \"\", sent)\n",
    "    tokens = kiwi.analyze(clean_sent)[0][0]\n",
    "    sub_list = []\n",
    "\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        pos = token.tag\n",
    "\n",
    "        if pos == \"NNG\" and len(word) > 1:\n",
    "            sub_list.append(word)\n",
    "\n",
    "    word_list2.extend(sub_list)\n",
    "\n",
    "print(len(word_list2))\n",
    "\n",
    "counter2 = Counter(word_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f94f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "wc = WordCloud(\n",
    "    font_path=\"C:\\Windows\\Fonts\\malgun.ttf\",\n",
    "    background_color=\"white\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    prefer_horizontal=1.0,\n",
    ")\n",
    "\n",
    "wc.generate_from_frequencies(counter2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea82d2",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_df=0.1, min_df=2, max_features=1000, ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "feat_vec = count_vectorizer.fit_transform(word_list2)\n",
    "feat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_vec = pd.DataFrame(\n",
    "    feat_vec.toarray(), columns=count_vectorizer.get_feature_names_out()\n",
    ")\n",
    "df_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3)\n",
    "lda.fit(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.lda_model\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.lda_model.prepare(lda, feat_vec, count_vectorizer)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "00a5f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.save_html(vis, \"lda_vis2.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca73a4a",
   "metadata": {},
   "source": [
    "## https://www.youtube.com/watch?v=PfseJBL9Vl0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c28d9",
   "metadata": {},
   "source": [
    "### 유튜브 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "baseUrl = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "\n",
    "part = \"snippet\"\n",
    "videoId = \"PfseJBL9Vl0\"\n",
    "key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "maxResults = 100\n",
    "textFormat = \"plainText\"\n",
    "nextPageToken = None\n",
    "\n",
    "dataList3 = []\n",
    "max_rep = 50\n",
    "\n",
    "for i in range(max_rep):\n",
    "    url = f\"{baseUrl}?part={part}&videoId={videoId}&key={key}&maxResults={maxResults}&textFormat={textFormat}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        nextPageToken = data.get(\"nextPageToken\")\n",
    "\n",
    "        for i in range(len(data[\"items\"])):\n",
    "            dataList3.append(data[\"items\"][i][\"snippet\"][\"topLevelComment\"][\"snippet\"])\n",
    "\n",
    "        if nextPageToken is None:\n",
    "            break\n",
    "\n",
    "print(len(dataList3))\n",
    "\n",
    "df = pd.DataFrame(dataList3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e9bb4",
   "metadata": {},
   "source": [
    "### 워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c603a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "from kiwipiepy import Kiwi\n",
    "import re\n",
    "\n",
    "kiwi = Kiwi()\n",
    "word_list3 = []\n",
    "\n",
    "for sent in df[\"textOriginal\"]:\n",
    "    clean_sent = re.sub(\"[^0-9a-zA-Z가-힣\\s]\", \"\", sent)\n",
    "    tokens = kiwi.analyze(clean_sent)[0][0]\n",
    "    sub_list = []\n",
    "\n",
    "    for token in tokens:\n",
    "        word = token.form\n",
    "        pos = token.tag\n",
    "\n",
    "        if pos == \"NNG\" and len(word) > 1:\n",
    "            sub_list.append(word)\n",
    "\n",
    "    word_list3.extend(sub_list)\n",
    "\n",
    "print(len(word_list3))\n",
    "\n",
    "counter3 = Counter(word_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e83613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "wc = WordCloud(\n",
    "    font_path=\"C:\\Windows\\Fonts\\malgun.ttf\",\n",
    "    background_color=\"white\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    prefer_horizontal=1.0,\n",
    ")\n",
    "\n",
    "wc.generate_from_frequencies(counter3)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56634420",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4710b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_df=0.1, min_df=2, max_features=1000, ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "feat_vec = count_vectorizer.fit_transform(word_list3)\n",
    "feat_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_vec = pd.DataFrame(\n",
    "    feat_vec.toarray(), columns=count_vectorizer.get_feature_names_out()\n",
    ")\n",
    "df_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3)\n",
    "lda.fit(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.lda_model\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.lda_model.prepare(lda, feat_vec, count_vectorizer)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5263db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.save_html(vis, \"lda_vis3.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
